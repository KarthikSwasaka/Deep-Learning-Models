{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "SepalLengthCm    0\n",
       "SepalWidthCm     0\n",
       "PetalLengthCm    0\n",
       "PetalWidthCm     0\n",
       "Species          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Species', axis = 1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units =4, activation = 'relu', input_shape = [4,]))\n",
    "model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 2s 13ms/sample - loss: 1.1425 - accuracy: 0.1417 - val_loss: 1.1496 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 1.1399 - accuracy: 0.1667 - val_loss: 1.1468 - val_accuracy: 0.2333\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.1371 - accuracy: 0.1917 - val_loss: 1.1443 - val_accuracy: 0.2333\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.1346 - accuracy: 0.2083 - val_loss: 1.1418 - val_accuracy: 0.2333\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.1322 - accuracy: 0.2250 - val_loss: 1.1392 - val_accuracy: 0.2000\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.1298 - accuracy: 0.2167 - val_loss: 1.1366 - val_accuracy: 0.1333\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.1275 - accuracy: 0.1917 - val_loss: 1.1340 - val_accuracy: 0.0667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 1.1252 - accuracy: 0.1667 - val_loss: 1.1316 - val_accuracy: 0.1000\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.1231 - accuracy: 0.1500 - val_loss: 1.1292 - val_accuracy: 0.1000\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.1210 - accuracy: 0.1250 - val_loss: 1.1269 - val_accuracy: 0.1000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.1189 - accuracy: 0.0917 - val_loss: 1.1243 - val_accuracy: 0.1000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 1.1167 - accuracy: 0.0667 - val_loss: 1.1219 - val_accuracy: 0.0667\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.1145 - accuracy: 0.0500 - val_loss: 1.1194 - val_accuracy: 0.0667\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.1124 - accuracy: 0.0333 - val_loss: 1.1169 - val_accuracy: 0.0667\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 1.1102 - accuracy: 0.0250 - val_loss: 1.1145 - val_accuracy: 0.0667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.1079 - accuracy: 0.0333 - val_loss: 1.1124 - val_accuracy: 0.0667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 1.1061 - accuracy: 0.0250 - val_loss: 1.1103 - val_accuracy: 0.0667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.1038 - accuracy: 0.0333 - val_loss: 1.1082 - val_accuracy: 0.0667\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.1017 - accuracy: 0.0333 - val_loss: 1.1060 - val_accuracy: 0.0667\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0995 - accuracy: 0.0333 - val_loss: 1.1038 - val_accuracy: 0.0667\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.0975 - accuracy: 0.0417 - val_loss: 1.1018 - val_accuracy: 0.1333\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0957 - accuracy: 0.0500 - val_loss: 1.0997 - val_accuracy: 0.1333\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 1.0940 - accuracy: 0.0833 - val_loss: 1.0978 - val_accuracy: 0.1667\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 1.0924 - accuracy: 0.1000 - val_loss: 1.0958 - val_accuracy: 0.1667\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 1.0906 - accuracy: 0.1333 - val_loss: 1.0941 - val_accuracy: 0.2333\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0889 - accuracy: 0.1917 - val_loss: 1.0923 - val_accuracy: 0.2667\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0872 - accuracy: 0.2167 - val_loss: 1.0906 - val_accuracy: 0.3000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 1.0854 - accuracy: 0.2333 - val_loss: 1.0888 - val_accuracy: 0.3000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0837 - accuracy: 0.2667 - val_loss: 1.0870 - val_accuracy: 0.3000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 1.0819 - accuracy: 0.2917 - val_loss: 1.0853 - val_accuracy: 0.3333\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0801 - accuracy: 0.3167 - val_loss: 1.0836 - val_accuracy: 0.3333\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0783 - accuracy: 0.3833 - val_loss: 1.0819 - val_accuracy: 0.3333\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0765 - accuracy: 0.4417 - val_loss: 1.0801 - val_accuracy: 0.3333\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.0746 - accuracy: 0.4833 - val_loss: 1.0782 - val_accuracy: 0.3333\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0727 - accuracy: 0.5083 - val_loss: 1.0764 - val_accuracy: 0.3333\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0708 - accuracy: 0.5583 - val_loss: 1.0745 - val_accuracy: 0.3667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0688 - accuracy: 0.5833 - val_loss: 1.0727 - val_accuracy: 0.3667\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.0668 - accuracy: 0.6000 - val_loss: 1.0708 - val_accuracy: 0.3667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0647 - accuracy: 0.6083 - val_loss: 1.0688 - val_accuracy: 0.4000\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0625 - accuracy: 0.6083 - val_loss: 1.0667 - val_accuracy: 0.4667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0603 - accuracy: 0.6083 - val_loss: 1.0645 - val_accuracy: 0.4667\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0580 - accuracy: 0.6083 - val_loss: 1.0623 - val_accuracy: 0.4667\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0556 - accuracy: 0.6167 - val_loss: 1.0599 - val_accuracy: 0.5000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0533 - accuracy: 0.6167 - val_loss: 1.0575 - val_accuracy: 0.5000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 1.0506 - accuracy: 0.6250 - val_loss: 1.0549 - val_accuracy: 0.5000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0480 - accuracy: 0.6250 - val_loss: 1.0522 - val_accuracy: 0.5000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 1.0451 - accuracy: 0.6333 - val_loss: 1.0496 - val_accuracy: 0.5333\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.0426 - accuracy: 0.6417 - val_loss: 1.0470 - val_accuracy: 0.5333\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0394 - accuracy: 0.6417 - val_loss: 1.0442 - val_accuracy: 0.5333\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0363 - accuracy: 0.6500 - val_loss: 1.0413 - val_accuracy: 0.5333\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0333 - accuracy: 0.6583 - val_loss: 1.0381 - val_accuracy: 0.5333\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 1.0302 - accuracy: 0.6583 - val_loss: 1.0349 - val_accuracy: 0.5333\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.0269 - accuracy: 0.6583 - val_loss: 1.0317 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 1.0232 - accuracy: 0.6583 - val_loss: 1.0284 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0201 - accuracy: 0.6583 - val_loss: 1.0249 - val_accuracy: 0.5667\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0163 - accuracy: 0.6583 - val_loss: 1.0215 - val_accuracy: 0.5667\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0130 - accuracy: 0.6583 - val_loss: 1.0180 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0089 - accuracy: 0.6583 - val_loss: 1.0144 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0052 - accuracy: 0.6667 - val_loss: 1.0107 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0012 - accuracy: 0.6667 - val_loss: 1.0068 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9975 - accuracy: 0.6667 - val_loss: 1.0028 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9930 - accuracy: 0.6667 - val_loss: 0.9988 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.9892 - accuracy: 0.6667 - val_loss: 0.9946 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9850 - accuracy: 0.6667 - val_loss: 0.9905 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9806 - accuracy: 0.6667 - val_loss: 0.9864 - val_accuracy: 0.5667\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9764 - accuracy: 0.6667 - val_loss: 0.9820 - val_accuracy: 0.5667\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9720 - accuracy: 0.6667 - val_loss: 0.9776 - val_accuracy: 0.5667\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9674 - accuracy: 0.6667 - val_loss: 0.9734 - val_accuracy: 0.5667\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9633 - accuracy: 0.6750 - val_loss: 0.9693 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.9592 - accuracy: 0.6750 - val_loss: 0.9652 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9550 - accuracy: 0.6750 - val_loss: 0.9613 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.9510 - accuracy: 0.6750 - val_loss: 0.9572 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9466 - accuracy: 0.6750 - val_loss: 0.9533 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9426 - accuracy: 0.6833 - val_loss: 0.9494 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.9385 - accuracy: 0.6833 - val_loss: 0.9455 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.9345 - accuracy: 0.6833 - val_loss: 0.9418 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9303 - accuracy: 0.6833 - val_loss: 0.9379 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9264 - accuracy: 0.7000 - val_loss: 0.9340 - val_accuracy: 0.6667\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.9221 - accuracy: 0.7000 - val_loss: 0.9300 - val_accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9182 - accuracy: 0.7167 - val_loss: 0.9262 - val_accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9141 - accuracy: 0.7250 - val_loss: 0.9224 - val_accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9101 - accuracy: 0.7333 - val_loss: 0.9186 - val_accuracy: 0.7000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9063 - accuracy: 0.7333 - val_loss: 0.9150 - val_accuracy: 0.7000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9022 - accuracy: 0.7333 - val_loss: 0.9112 - val_accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8982 - accuracy: 0.7333 - val_loss: 0.9073 - val_accuracy: 0.7000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.8943 - accuracy: 0.7500 - val_loss: 0.9038 - val_accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8904 - accuracy: 0.7500 - val_loss: 0.9000 - val_accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8864 - accuracy: 0.7583 - val_loss: 0.8963 - val_accuracy: 0.7000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8826 - accuracy: 0.7583 - val_loss: 0.8926 - val_accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.8786 - accuracy: 0.7583 - val_loss: 0.8889 - val_accuracy: 0.7333\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8747 - accuracy: 0.7667 - val_loss: 0.8853 - val_accuracy: 0.7333\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8708 - accuracy: 0.7667 - val_loss: 0.8817 - val_accuracy: 0.7333\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8670 - accuracy: 0.7667 - val_loss: 0.8782 - val_accuracy: 0.7333\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8633 - accuracy: 0.7583 - val_loss: 0.8750 - val_accuracy: 0.7000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.8593 - accuracy: 0.7667 - val_loss: 0.8715 - val_accuracy: 0.7667\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.8556 - accuracy: 0.7667 - val_loss: 0.8679 - val_accuracy: 0.7667\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.8517 - accuracy: 0.7667 - val_loss: 0.8644 - val_accuracy: 0.7667\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.8480 - accuracy: 0.7667 - val_loss: 0.8609 - val_accuracy: 0.7667\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.8443 - accuracy: 0.7750 - val_loss: 0.8574 - val_accuracy: 0.7667\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.8406 - accuracy: 0.7750 - val_loss: 0.8539 - val_accuracy: 0.7667\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8369 - accuracy: 0.7750 - val_loss: 0.8505 - val_accuracy: 0.7667\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8332 - accuracy: 0.7750 - val_loss: 0.8471 - val_accuracy: 0.8000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8297 - accuracy: 0.7833 - val_loss: 0.8437 - val_accuracy: 0.8000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8259 - accuracy: 0.7833 - val_loss: 0.8404 - val_accuracy: 0.8000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8225 - accuracy: 0.7917 - val_loss: 0.8371 - val_accuracy: 0.8000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8189 - accuracy: 0.8083 - val_loss: 0.8337 - val_accuracy: 0.8000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8152 - accuracy: 0.8167 - val_loss: 0.8304 - val_accuracy: 0.8000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8118 - accuracy: 0.8250 - val_loss: 0.8271 - val_accuracy: 0.8000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8083 - accuracy: 0.8250 - val_loss: 0.8238 - val_accuracy: 0.8000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8047 - accuracy: 0.8333 - val_loss: 0.8205 - val_accuracy: 0.8000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8012 - accuracy: 0.8500 - val_loss: 0.8174 - val_accuracy: 0.8000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7978 - accuracy: 0.8417 - val_loss: 0.8144 - val_accuracy: 0.8000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7944 - accuracy: 0.8417 - val_loss: 0.8114 - val_accuracy: 0.8000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.7910 - accuracy: 0.8417 - val_loss: 0.8082 - val_accuracy: 0.8000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7877 - accuracy: 0.8500 - val_loss: 0.8051 - val_accuracy: 0.8333\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7842 - accuracy: 0.8500 - val_loss: 0.8020 - val_accuracy: 0.8333\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7809 - accuracy: 0.8500 - val_loss: 0.7989 - val_accuracy: 0.8333\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7775 - accuracy: 0.8500 - val_loss: 0.7960 - val_accuracy: 0.8333\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7742 - accuracy: 0.8500 - val_loss: 0.7930 - val_accuracy: 0.8333\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7709 - accuracy: 0.8500 - val_loss: 0.7901 - val_accuracy: 0.8333\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7676 - accuracy: 0.8417 - val_loss: 0.7874 - val_accuracy: 0.8333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7644 - accuracy: 0.8417 - val_loss: 0.7846 - val_accuracy: 0.8333\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7611 - accuracy: 0.8333 - val_loss: 0.7819 - val_accuracy: 0.8333\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7578 - accuracy: 0.8250 - val_loss: 0.7791 - val_accuracy: 0.8333\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7546 - accuracy: 0.8250 - val_loss: 0.7762 - val_accuracy: 0.8667\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7514 - accuracy: 0.8250 - val_loss: 0.7733 - val_accuracy: 0.8667\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7481 - accuracy: 0.8250 - val_loss: 0.7703 - val_accuracy: 0.8667\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7450 - accuracy: 0.8250 - val_loss: 0.7675 - val_accuracy: 0.8667\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7418 - accuracy: 0.8167 - val_loss: 0.7647 - val_accuracy: 0.8667\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7387 - accuracy: 0.8167 - val_loss: 0.7618 - val_accuracy: 0.8667\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7355 - accuracy: 0.8167 - val_loss: 0.7590 - val_accuracy: 0.8667\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7323 - accuracy: 0.8167 - val_loss: 0.7562 - val_accuracy: 0.8667\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7292 - accuracy: 0.8167 - val_loss: 0.7535 - val_accuracy: 0.8667\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7261 - accuracy: 0.8167 - val_loss: 0.7509 - val_accuracy: 0.8667\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7230 - accuracy: 0.8083 - val_loss: 0.7482 - val_accuracy: 0.8667\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7200 - accuracy: 0.8083 - val_loss: 0.7455 - val_accuracy: 0.8667\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7168 - accuracy: 0.8083 - val_loss: 0.7428 - val_accuracy: 0.8667\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.7137 - accuracy: 0.8000 - val_loss: 0.7400 - val_accuracy: 0.8667\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7106 - accuracy: 0.8083 - val_loss: 0.7372 - val_accuracy: 0.8667\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7075 - accuracy: 0.8000 - val_loss: 0.7345 - val_accuracy: 0.8667\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7045 - accuracy: 0.8000 - val_loss: 0.7316 - val_accuracy: 0.8667\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.7013 - accuracy: 0.8000 - val_loss: 0.7288 - val_accuracy: 0.8667\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6983 - accuracy: 0.8000 - val_loss: 0.7261 - val_accuracy: 0.8667\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.6952 - accuracy: 0.8000 - val_loss: 0.7234 - val_accuracy: 0.8667\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6921 - accuracy: 0.8000 - val_loss: 0.7209 - val_accuracy: 0.8667\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.6890 - accuracy: 0.8000 - val_loss: 0.7182 - val_accuracy: 0.8667\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.6860 - accuracy: 0.8000 - val_loss: 0.7156 - val_accuracy: 0.8667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.6829 - accuracy: 0.7833 - val_loss: 0.7129 - val_accuracy: 0.8667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6798 - accuracy: 0.7833 - val_loss: 0.7102 - val_accuracy: 0.8667\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6766 - accuracy: 0.7833 - val_loss: 0.7075 - val_accuracy: 0.8667\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6736 - accuracy: 0.7833 - val_loss: 0.7048 - val_accuracy: 0.8667\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6704 - accuracy: 0.7833 - val_loss: 0.7021 - val_accuracy: 0.8667\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6674 - accuracy: 0.7833 - val_loss: 0.6995 - val_accuracy: 0.8667\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6642 - accuracy: 0.7833 - val_loss: 0.6969 - val_accuracy: 0.8667\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6611 - accuracy: 0.7833 - val_loss: 0.6941 - val_accuracy: 0.8667\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.6581 - accuracy: 0.7833 - val_loss: 0.6916 - val_accuracy: 0.8667\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6549 - accuracy: 0.7833 - val_loss: 0.6888 - val_accuracy: 0.8667\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6519 - accuracy: 0.7833 - val_loss: 0.6862 - val_accuracy: 0.8667\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6488 - accuracy: 0.7833 - val_loss: 0.6835 - val_accuracy: 0.8667\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6456 - accuracy: 0.7833 - val_loss: 0.6807 - val_accuracy: 0.8667\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.6426 - accuracy: 0.7667 - val_loss: 0.6781 - val_accuracy: 0.8667\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6394 - accuracy: 0.7583 - val_loss: 0.6754 - val_accuracy: 0.8667\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6364 - accuracy: 0.7583 - val_loss: 0.6728 - val_accuracy: 0.8667\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6333 - accuracy: 0.7583 - val_loss: 0.6701 - val_accuracy: 0.8667\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6302 - accuracy: 0.7500 - val_loss: 0.6674 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6271 - accuracy: 0.7583 - val_loss: 0.6647 - val_accuracy: 0.8667\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6241 - accuracy: 0.7583 - val_loss: 0.6621 - val_accuracy: 0.8667\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6211 - accuracy: 0.7583 - val_loss: 0.6592 - val_accuracy: 0.8667\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6179 - accuracy: 0.7583 - val_loss: 0.6566 - val_accuracy: 0.8667\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6149 - accuracy: 0.7583 - val_loss: 0.6540 - val_accuracy: 0.8667\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6118 - accuracy: 0.7583 - val_loss: 0.6515 - val_accuracy: 0.8667\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.6088 - accuracy: 0.7500 - val_loss: 0.6489 - val_accuracy: 0.8333\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6059 - accuracy: 0.7500 - val_loss: 0.6464 - val_accuracy: 0.8000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6027 - accuracy: 0.7500 - val_loss: 0.6438 - val_accuracy: 0.8000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.6414 - val_accuracy: 0.7667\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5967 - accuracy: 0.7500 - val_loss: 0.6387 - val_accuracy: 0.8000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5938 - accuracy: 0.7500 - val_loss: 0.6360 - val_accuracy: 0.8000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.5908 - accuracy: 0.7500 - val_loss: 0.6333 - val_accuracy: 0.8000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.75 - 0s 225us/sample - loss: 0.5878 - accuracy: 0.7500 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5849 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.8333\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5820 - accuracy: 0.7583 - val_loss: 0.6252 - val_accuracy: 0.8333\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5789 - accuracy: 0.7583 - val_loss: 0.6225 - val_accuracy: 0.8333\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5760 - accuracy: 0.7583 - val_loss: 0.6198 - val_accuracy: 0.8333\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.5731 - accuracy: 0.7667 - val_loss: 0.6171 - val_accuracy: 0.8333\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5702 - accuracy: 0.7583 - val_loss: 0.6146 - val_accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.5674 - accuracy: 0.7667 - val_loss: 0.6118 - val_accuracy: 0.8333\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 0.5644 - accuracy: 0.7667 - val_loss: 0.6090 - val_accuracy: 0.8667\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.5616 - accuracy: 0.7750 - val_loss: 0.6063 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5588 - accuracy: 0.7750 - val_loss: 0.6037 - val_accuracy: 0.8667\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5560 - accuracy: 0.7750 - val_loss: 0.6011 - val_accuracy: 0.8667\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5531 - accuracy: 0.7750 - val_loss: 0.5983 - val_accuracy: 0.8667\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5504 - accuracy: 0.7750 - val_loss: 0.5954 - val_accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5475 - accuracy: 0.7750 - val_loss: 0.5930 - val_accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5447 - accuracy: 0.7750 - val_loss: 0.5904 - val_accuracy: 0.8667\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5421 - accuracy: 0.7750 - val_loss: 0.5880 - val_accuracy: 0.8667\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5393 - accuracy: 0.7750 - val_loss: 0.5855 - val_accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5367 - accuracy: 0.7750 - val_loss: 0.5830 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5340 - accuracy: 0.7833 - val_loss: 0.5804 - val_accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5314 - accuracy: 0.7833 - val_loss: 0.5777 - val_accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5287 - accuracy: 0.7833 - val_loss: 0.5751 - val_accuracy: 0.8667\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5261 - accuracy: 0.7833 - val_loss: 0.5724 - val_accuracy: 0.9000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5235 - accuracy: 0.7833 - val_loss: 0.5699 - val_accuracy: 0.9000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5210 - accuracy: 0.7833 - val_loss: 0.5673 - val_accuracy: 0.9000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5184 - accuracy: 0.7833 - val_loss: 0.5648 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.5159 - accuracy: 0.7917 - val_loss: 0.5622 - val_accuracy: 0.9000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5134 - accuracy: 0.8000 - val_loss: 0.5597 - val_accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5109 - accuracy: 0.8000 - val_loss: 0.5570 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5084 - accuracy: 0.8167 - val_loss: 0.5546 - val_accuracy: 0.9000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.5060 - accuracy: 0.8250 - val_loss: 0.5521 - val_accuracy: 0.9000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5036 - accuracy: 0.8333 - val_loss: 0.5493 - val_accuracy: 0.9000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.5011 - accuracy: 0.8417 - val_loss: 0.5466 - val_accuracy: 0.9000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.4987 - accuracy: 0.8417 - val_loss: 0.5442 - val_accuracy: 0.9000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4963 - accuracy: 0.8417 - val_loss: 0.5417 - val_accuracy: 0.9000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.4940 - accuracy: 0.8500 - val_loss: 0.5392 - val_accuracy: 0.9000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4916 - accuracy: 0.8500 - val_loss: 0.5366 - val_accuracy: 0.9000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4893 - accuracy: 0.8583 - val_loss: 0.5341 - val_accuracy: 0.9000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.4870 - accuracy: 0.8667 - val_loss: 0.5318 - val_accuracy: 0.9000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.4847 - accuracy: 0.8667 - val_loss: 0.5295 - val_accuracy: 0.9000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4824 - accuracy: 0.8750 - val_loss: 0.5272 - val_accuracy: 0.9333\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4802 - accuracy: 0.8750 - val_loss: 0.5250 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4780 - accuracy: 0.8750 - val_loss: 0.5226 - val_accuracy: 0.9333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4759 - accuracy: 0.8750 - val_loss: 0.5204 - val_accuracy: 0.9333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4736 - accuracy: 0.8833 - val_loss: 0.5180 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.4714 - accuracy: 0.8833 - val_loss: 0.5157 - val_accuracy: 0.9333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4693 - accuracy: 0.8917 - val_loss: 0.5133 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4671 - accuracy: 0.8917 - val_loss: 0.5111 - val_accuracy: 0.9333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 0.4650 - accuracy: 0.8917 - val_loss: 0.5088 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.4630 - accuracy: 0.8917 - val_loss: 0.5069 - val_accuracy: 0.9333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4609 - accuracy: 0.8917 - val_loss: 0.5046 - val_accuracy: 0.9333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 0.4589 - accuracy: 0.8917 - val_loss: 0.5027 - val_accuracy: 0.9333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 0.4567 - accuracy: 0.8917 - val_loss: 0.5004 - val_accuracy: 0.9333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.4548 - accuracy: 0.9083 - val_loss: 0.4982 - val_accuracy: 0.9333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.4528 - accuracy: 0.9083 - val_loss: 0.4962 - val_accuracy: 0.9333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.4509 - accuracy: 0.9083 - val_loss: 0.4943 - val_accuracy: 0.9333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.4489 - accuracy: 0.9083 - val_loss: 0.4922 - val_accuracy: 0.9333\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4469 - accuracy: 0.9083 - val_loss: 0.4902 - val_accuracy: 0.9333\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.4451 - accuracy: 0.9083 - val_loss: 0.4880 - val_accuracy: 0.9333\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4432 - accuracy: 0.9083 - val_loss: 0.4859 - val_accuracy: 0.9333\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4413 - accuracy: 0.9167 - val_loss: 0.4839 - val_accuracy: 0.9333\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4395 - accuracy: 0.9167 - val_loss: 0.4819 - val_accuracy: 0.9333\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4377 - accuracy: 0.9167 - val_loss: 0.4801 - val_accuracy: 0.9333\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.4358 - accuracy: 0.9167 - val_loss: 0.4783 - val_accuracy: 0.9333\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.4341 - accuracy: 0.9167 - val_loss: 0.4762 - val_accuracy: 0.9333\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.4323 - accuracy: 0.9167 - val_loss: 0.4741 - val_accuracy: 0.9333\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4306 - accuracy: 0.9167 - val_loss: 0.4722 - val_accuracy: 0.9333\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4288 - accuracy: 0.9167 - val_loss: 0.4703 - val_accuracy: 0.9333\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4271 - accuracy: 0.9167 - val_loss: 0.4685 - val_accuracy: 0.9333\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.4254 - accuracy: 0.9250 - val_loss: 0.4665 - val_accuracy: 0.9333\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.4237 - accuracy: 0.9250 - val_loss: 0.4644 - val_accuracy: 0.9333\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.4221 - accuracy: 0.9250 - val_loss: 0.4623 - val_accuracy: 0.9333\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.4204 - accuracy: 0.9333 - val_loss: 0.4604 - val_accuracy: 0.9333\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.4187 - accuracy: 0.9333 - val_loss: 0.4589 - val_accuracy: 0.9333\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4171 - accuracy: 0.9333 - val_loss: 0.4571 - val_accuracy: 0.9333\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4154 - accuracy: 0.9333 - val_loss: 0.4554 - val_accuracy: 0.9333\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4139 - accuracy: 0.9333 - val_loss: 0.4537 - val_accuracy: 0.9333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4122 - accuracy: 0.9333 - val_loss: 0.4518 - val_accuracy: 0.9333\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4107 - accuracy: 0.9333 - val_loss: 0.4499 - val_accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4091 - accuracy: 0.9333 - val_loss: 0.4481 - val_accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4076 - accuracy: 0.9333 - val_loss: 0.4462 - val_accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4060 - accuracy: 0.9417 - val_loss: 0.4445 - val_accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.4045 - accuracy: 0.9417 - val_loss: 0.4428 - val_accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.4029 - accuracy: 0.9417 - val_loss: 0.4411 - val_accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4014 - accuracy: 0.9417 - val_loss: 0.4395 - val_accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.3999 - accuracy: 0.9417 - val_loss: 0.4377 - val_accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.3984 - accuracy: 0.9417 - val_loss: 0.4359 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.3969 - accuracy: 0.9417 - val_loss: 0.4344 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3956 - accuracy: 0.9417 - val_loss: 0.4325 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.3940 - accuracy: 0.9417 - val_loss: 0.4309 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.3926 - accuracy: 0.9417 - val_loss: 0.4292 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.3911 - accuracy: 0.9417 - val_loss: 0.4279 - val_accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3897 - accuracy: 0.9417 - val_loss: 0.4264 - val_accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3882 - accuracy: 0.9417 - val_loss: 0.4249 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3869 - accuracy: 0.9417 - val_loss: 0.4236 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.3854 - accuracy: 0.9417 - val_loss: 0.4222 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3840 - accuracy: 0.9417 - val_loss: 0.4205 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3828 - accuracy: 0.9417 - val_loss: 0.4187 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.3813 - accuracy: 0.9417 - val_loss: 0.4172 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.3799 - accuracy: 0.9417 - val_loss: 0.4158 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3786 - accuracy: 0.9417 - val_loss: 0.4142 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3772 - accuracy: 0.9417 - val_loss: 0.4127 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.3759 - accuracy: 0.9417 - val_loss: 0.4113 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3747 - accuracy: 0.9417 - val_loss: 0.4096 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.3733 - accuracy: 0.9500 - val_loss: 0.4084 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.3719 - accuracy: 0.9417 - val_loss: 0.4070 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.3706 - accuracy: 0.9500 - val_loss: 0.4057 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.3693 - accuracy: 0.9500 - val_loss: 0.4043 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.3681 - accuracy: 0.9500 - val_loss: 0.4027 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.3668 - accuracy: 0.9500 - val_loss: 0.4014 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3655 - accuracy: 0.9500 - val_loss: 0.3999 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3642 - accuracy: 0.9500 - val_loss: 0.3985 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.3631 - accuracy: 0.9500 - val_loss: 0.3968 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.3617 - accuracy: 0.9583 - val_loss: 0.3956 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.3605 - accuracy: 0.9583 - val_loss: 0.3942 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.3593 - accuracy: 0.9583 - val_loss: 0.3930 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.3580 - accuracy: 0.9583 - val_loss: 0.3915 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.3569 - accuracy: 0.9583 - val_loss: 0.3900 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.3557 - accuracy: 0.9583 - val_loss: 0.3890 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.3544 - accuracy: 0.9583 - val_loss: 0.3876 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.3532 - accuracy: 0.9583 - val_loss: 0.3863 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.3521 - accuracy: 0.9583 - val_loss: 0.3848 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6fd248908>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x =scaled_X_train,y = y_train,epochs = 300, validation_data = (scaled_X_test, y_test), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'accuracy', 'val_loss', 'val_accuracy'], dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.142521</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>1.149645</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.139866</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.146818</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.137122</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>1.144278</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.134565</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.141802</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.132239</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1.139158</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.142521  0.141667  1.149645      0.266667\n",
       "1  1.139866  0.166667  1.146818      0.233333\n",
       "2  1.137122  0.191667  1.144278      0.233333\n",
       "3  1.134565  0.208333  1.141802      0.233333\n",
       "4  1.132239  0.225000  1.139158      0.200000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3848022520542145, 0.96666664]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units =4, activation = 'relu', input_shape = [4,]))\n",
    "model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 1.0220 - accuracy: 0.2467\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 1.0177 - accuracy: 0.2800\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 1.0127 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 1.0083 - accuracy: 0.3533\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 1.0039 - accuracy: 0.3400\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9992 - accuracy: 0.3467\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9948 - accuracy: 0.3467\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9900 - accuracy: 0.3467\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9852 - accuracy: 0.3533\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.9804 - accuracy: 0.3667\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9755 - accuracy: 0.3600\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9711 - accuracy: 0.3600\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9659 - accuracy: 0.3800\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.9613 - accuracy: 0.3867\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9564 - accuracy: 0.3933\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9513 - accuracy: 0.4267\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9467 - accuracy: 0.4533\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9417 - accuracy: 0.4533\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.9371 - accuracy: 0.4600\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9322 - accuracy: 0.4667\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.9272 - accuracy: 0.4667\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9225 - accuracy: 0.4867\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9176 - accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.9128 - accuracy: 0.5000\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.9077 - accuracy: 0.5333\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.9031 - accuracy: 0.5333\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.8984 - accuracy: 0.5533\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.8938 - accuracy: 0.5667\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8895 - accuracy: 0.5733\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8852 - accuracy: 0.5867\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.8811 - accuracy: 0.5867\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.8771 - accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8731 - accuracy: 0.6067\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.8691 - accuracy: 0.6133\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8654 - accuracy: 0.6200\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8617 - accuracy: 0.6200\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8509 - accuracy: 0.59 - 0s 120us/sample - loss: 0.8580 - accuracy: 0.6333\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.8542 - accuracy: 0.6400\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8506 - accuracy: 0.6400\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.8470 - accuracy: 0.6467\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 157us/sample - loss: 0.8433 - accuracy: 0.6467\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8398 - accuracy: 0.6533\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.8361 - accuracy: 0.6600\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8326 - accuracy: 0.6600\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.68 - 0s 115us/sample - loss: 0.8291 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8255 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8221 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.8188 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.8154 - accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.8121 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.8089 - accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8057 - accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.8026 - accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.7994 - accuracy: 0.6733\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7962 - accuracy: 0.6733\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7932 - accuracy: 0.6733\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.7902 - accuracy: 0.6867\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.7872 - accuracy: 0.6867\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 148us/sample - loss: 0.7842 - accuracy: 0.6867\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.7812 - accuracy: 0.6867\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.7783 - accuracy: 0.6867\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.7755 - accuracy: 0.6867\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.7727 - accuracy: 0.6867\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.7697 - accuracy: 0.6867\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7671 - accuracy: 0.6867\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7642 - accuracy: 0.6867\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 143us/sample - loss: 0.7615 - accuracy: 0.6867\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.7587 - accuracy: 0.6867\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7559 - accuracy: 0.6867\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7534 - accuracy: 0.6867\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7506 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7480 - accuracy: 0.6933\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.7454 - accuracy: 0.6933\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7429 - accuracy: 0.6933\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7404 - accuracy: 0.6933\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7378 - accuracy: 0.6933\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 128us/sample - loss: 0.7354 - accuracy: 0.6933\n",
      "Epoch 78/300\n",
      "150/150 [==============================] - 0s 136us/sample - loss: 0.7329 - accuracy: 0.6933\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.7305 - accuracy: 0.6933\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.7280 - accuracy: 0.6933\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7256 - accuracy: 0.6933\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.7233 - accuracy: 0.6933\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.7209 - accuracy: 0.6933\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7186 - accuracy: 0.6933\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7162 - accuracy: 0.6933\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.7139 - accuracy: 0.6933\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.7116 - accuracy: 0.6933\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.7094 - accuracy: 0.6933\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.7071 - accuracy: 0.6933\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.7048 - accuracy: 0.6933\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7026 - accuracy: 0.6933\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7005 - accuracy: 0.6933\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.6983 - accuracy: 0.6933\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.6961 - accuracy: 0.6933\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 274us/sample - loss: 0.6939 - accuracy: 0.6933\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 353us/sample - loss: 0.6919 - accuracy: 0.7000\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 573us/sample - loss: 0.6898 - accuracy: 0.7000\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.6875 - accuracy: 0.7000\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.6856 - accuracy: 0.7000\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.6835 - accuracy: 0.7000\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 167us/sample - loss: 0.6816 - accuracy: 0.7000\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6794 - accuracy: 0.7000\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6774 - accuracy: 0.7000\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.6754 - accuracy: 0.7000\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.6735 - accuracy: 0.7000\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.6715 - accuracy: 0.7000\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6696 - accuracy: 0.7000\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6676 - accuracy: 0.7000\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6658 - accuracy: 0.7067\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6639 - accuracy: 0.7067\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6621 - accuracy: 0.7067\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6604 - accuracy: 0.7067\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.6584 - accuracy: 0.7133\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6566 - accuracy: 0.7133\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6549 - accuracy: 0.7133\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.6530 - accuracy: 0.7133\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6514 - accuracy: 0.7133\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6495 - accuracy: 0.7133\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6479 - accuracy: 0.7133\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6461 - accuracy: 0.7200\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6444 - accuracy: 0.7133\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6426 - accuracy: 0.7133\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.6409 - accuracy: 0.7133\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6393 - accuracy: 0.7200\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6376 - accuracy: 0.7267\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.6359 - accuracy: 0.7267\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.6343 - accuracy: 0.7267\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6326 - accuracy: 0.7267\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6309 - accuracy: 0.7333\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6293 - accuracy: 0.7400\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6277 - accuracy: 0.7400\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.6261 - accuracy: 0.7400\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6245 - accuracy: 0.7400\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6228 - accuracy: 0.7400\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.6214 - accuracy: 0.7400\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6199 - accuracy: 0.7400\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.6185 - accuracy: 0.7400\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.6167 - accuracy: 0.7400\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.6151 - accuracy: 0.7400\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 187us/sample - loss: 0.6138 - accuracy: 0.7400\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.6123 - accuracy: 0.7400\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 181us/sample - loss: 0.6107 - accuracy: 0.7400\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.6091 - accuracy: 0.7400\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.6078 - accuracy: 0.7400\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6062 - accuracy: 0.7400\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.6047 - accuracy: 0.7467\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6033 - accuracy: 0.7533\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6018 - accuracy: 0.7467\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.6004 - accuracy: 0.7600\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5990 - accuracy: 0.7667\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5976 - accuracy: 0.7667\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.5962 - accuracy: 0.7667\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 143us/sample - loss: 0.5948 - accuracy: 0.7733\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.5935 - accuracy: 0.7733\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5920 - accuracy: 0.7733\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5907 - accuracy: 0.7800\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.5893 - accuracy: 0.7933\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5879 - accuracy: 0.7933\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5866 - accuracy: 0.7933\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.5853 - accuracy: 0.7933\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.5839 - accuracy: 0.7933\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.5826 - accuracy: 0.7933\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5812 - accuracy: 0.7933\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5799 - accuracy: 0.8067\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5786 - accuracy: 0.8067\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5773 - accuracy: 0.8200\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5760 - accuracy: 0.8200\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.87 - 0s 127us/sample - loss: 0.5748 - accuracy: 0.8200\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5734 - accuracy: 0.8200\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 0.5722 - accuracy: 0.8200\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5710 - accuracy: 0.8200\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.5697 - accuracy: 0.8200\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5684 - accuracy: 0.8200\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5672 - accuracy: 0.8200\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5659 - accuracy: 0.8200\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5647 - accuracy: 0.8200\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5636 - accuracy: 0.8200\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5622 - accuracy: 0.8200\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5610 - accuracy: 0.8200\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.5597 - accuracy: 0.8200\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5586 - accuracy: 0.8200\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5574 - accuracy: 0.8200\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 207us/sample - loss: 0.5562 - accuracy: 0.8200\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5550 - accuracy: 0.8200\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.5537 - accuracy: 0.8200\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.5527 - accuracy: 0.8200\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5514 - accuracy: 0.8200\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5502 - accuracy: 0.8200\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.5490 - accuracy: 0.8200\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5478 - accuracy: 0.8200\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5467 - accuracy: 0.8200\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5455 - accuracy: 0.8200\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5443 - accuracy: 0.8200\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5434 - accuracy: 0.8200\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5420 - accuracy: 0.8200\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5409 - accuracy: 0.8200\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5397 - accuracy: 0.8200\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.5386 - accuracy: 0.8200\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5375 - accuracy: 0.8200\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.5364 - accuracy: 0.8200\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.5352 - accuracy: 0.8200\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5341 - accuracy: 0.8200\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5331 - accuracy: 0.8200\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.5318 - accuracy: 0.8200\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5307 - accuracy: 0.8200\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5297 - accuracy: 0.8200\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5285 - accuracy: 0.8200\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.5274 - accuracy: 0.8200\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5263 - accuracy: 0.8267\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5253 - accuracy: 0.8267\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.71 - 0s 113us/sample - loss: 0.5241 - accuracy: 0.8267\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.5230 - accuracy: 0.8333\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.5220 - accuracy: 0.8267\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5209 - accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5198 - accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5187 - accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5178 - accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.5165 - accuracy: 0.8333\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5155 - accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.5144 - accuracy: 0.8333\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.5134 - accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5122 - accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5112 - accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 136us/sample - loss: 0.5101 - accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.5091 - accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5080 - accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.5070 - accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5059 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.5048 - accuracy: 0.8400\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5038 - accuracy: 0.8400\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5028 - accuracy: 0.8400\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5017 - accuracy: 0.8400\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5007 - accuracy: 0.8400\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 135us/sample - loss: 0.4997 - accuracy: 0.8400\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4987 - accuracy: 0.8400\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4976 - accuracy: 0.8400\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4966 - accuracy: 0.8400\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.4956 - accuracy: 0.8400\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4945 - accuracy: 0.8400\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4935 - accuracy: 0.8400\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.4925 - accuracy: 0.8400\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.4914 - accuracy: 0.8400\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4905 - accuracy: 0.8400\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4894 - accuracy: 0.8400\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4884 - accuracy: 0.8400\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4875 - accuracy: 0.8467\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4864 - accuracy: 0.8467\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4853 - accuracy: 0.8467\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4844 - accuracy: 0.8467\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 135us/sample - loss: 0.4833 - accuracy: 0.8467\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.4823 - accuracy: 0.8467\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4813 - accuracy: 0.8467\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4803 - accuracy: 0.8467\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4793 - accuracy: 0.8467\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4785 - accuracy: 0.8467\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.90 - 0s 119us/sample - loss: 0.4774 - accuracy: 0.8467\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4764 - accuracy: 0.8533\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4753 - accuracy: 0.8533\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4743 - accuracy: 0.8533\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4734 - accuracy: 0.8467\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4724 - accuracy: 0.8533\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4713 - accuracy: 0.8533\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.4704 - accuracy: 0.8533\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.4693 - accuracy: 0.8533\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4684 - accuracy: 0.8533\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4674 - accuracy: 0.8600\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4664 - accuracy: 0.8533\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4655 - accuracy: 0.8533\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4645 - accuracy: 0.8533\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4637 - accuracy: 0.8533\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.4626 - accuracy: 0.8600\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4617 - accuracy: 0.8600\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 195us/sample - loss: 0.4606 - accuracy: 0.8667\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4595 - accuracy: 0.8667\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4587 - accuracy: 0.8667\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.4576 - accuracy: 0.8667\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4566 - accuracy: 0.8667\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4557 - accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4547 - accuracy: 0.8733\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4537 - accuracy: 0.8733\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4529 - accuracy: 0.8667\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.4518 - accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4509 - accuracy: 0.8733\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4501 - accuracy: 0.8867\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.4489 - accuracy: 0.8867\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4481 - accuracy: 0.8800\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4470 - accuracy: 0.8800\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4461 - accuracy: 0.8800\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.4453 - accuracy: 0.8800\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4442 - accuracy: 0.8867\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4433 - accuracy: 0.8867\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.4424 - accuracy: 0.8867\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4415 - accuracy: 0.8867\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4404 - accuracy: 0.8867\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4396 - accuracy: 0.8867\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.4386 - accuracy: 0.8867\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4376 - accuracy: 0.8867\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4367 - accuracy: 0.8867\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4357 - accuracy: 0.8867\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4348 - accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6fcf77e08>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_test,y,epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iris_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('iris_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'SepalLengthCm': 5.1, 'SepalWidthCm':3.5, 'PetalLengthCm':1.4, 'PetalWidthCm':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking my model\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json['SepalLengthCm']\n",
    "    s_wid = sample_json['SepalWidthCm']\n",
    "    p_len = sample_json['PetalLengthCm']\n",
    "    p_wid = sample_json['PetalWidthCm']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
